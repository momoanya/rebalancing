{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Munge Information\n",
    "The result of bringing together the ETF spreadsheets and TD Mutual Fund CSVs is a complete DataFrame that is pickled in file historical_prices.pickle. \n",
    "\n",
    "This can be loaded as price_history. See the last few cells to shortcut the munge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF Data\n",
    "This section will convert the etf spreadsheets from iShares into usable data and store this information in an SQLite database. \n",
    "The etf excel spreadsheets are stored in a subdirectory called etf_data.\n",
    "\n",
    "It is necessary to ensure each file is resaved into a modern xlsx format, as they are usually in a 2003 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using the os 'listdir' method to return filenames in the subdirectory\n",
    "path = './etf_data'\n",
    "etf_files = os.listdir(path)\n",
    "\n",
    "# set the security symbols in the same order\n",
    "# as the file names in the directory\n",
    "etf_symbol = ['XSB', 'XBB', 'XSP', 'XIC', 'XIN', 'XIU']\n",
    "etf_asset_class = ['Fixed Income', 'Fixed Income', \n",
    "                   'Equity', 'Equity', 'Equity', 'Equity'\n",
    "                  ] \n",
    "\n",
    "etf_geography = ['Canadian', 'Canadian', 'United States', \n",
    "                 'Canadian', 'International', 'Canadian'\n",
    "                ]\n",
    "# combine the two list above into a dictionary with the etf symbol as the key.\n",
    "etf_details = zip(etf_files, etf_asset_class, etf_geography)\n",
    "etf_dict = dict(zip(etf_symbol, etf_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('iShares-Core-Canadian-Short-Term-Bond-Index-ETF_fund.xlsx',\n",
       " 'Fixed Income',\n",
       " 'Canadian')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etf_symbol, etf_asset_class, etf_geography, etf_files\n",
    "etf_dict['XSB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize etf_df as none\n",
    "etf_df = None\n",
    "\n",
    "# loop through all the spreadsheets downloaded from iShares and create\n",
    "# one dataframe with all the historical pricing and distribution\n",
    "# information for dates going back to early 2000's\n",
    "\n",
    "for symbol in etf_dict:\n",
    "    file_name = etf_dict[symbol][0]\n",
    "    asset_class = etf_dict[symbol][1]\n",
    "    geography = etf_dict[symbol][2]\n",
    "\n",
    "# The 'iShares-MSCI-EAFE-Index-ETF-CAD-Hedged_fund.xlsx' sheet only\n",
    "# has three columns under the historical sheet, omitting the\n",
    "# return-index column. Adjust the columns used when opening\n",
    "# the file under read_excel so that the right columns are imported\n",
    "    if file_name == 'iShares-MSCI-EAFE-Index-ETF-CAD-Hedged_fund.xlsx':\n",
    "        use_columns = [0, 1, 2]\n",
    "    else:\n",
    "        use_columns = [0, 2, 3]\n",
    "\n",
    "    # open spread sheet and read the data into df\n",
    "    df = pd.read_excel('etf_data/' + file_name,\n",
    "                       sheet_name='Historical',\n",
    "                       usecols=use_columns,\n",
    "                       names=['trade_date', 'nav_per_share', 'dividends'],\n",
    "                       na_values=\"--\",\n",
    "                       converters={'As Of': pd.to_datetime}\n",
    "                       )\n",
    "    # set values in the df for symbol\n",
    "    df['security'] = symbol\n",
    "    \n",
    "    # set values for asset class\n",
    "    df['asset_class'] = asset_class\n",
    "\n",
    "    # set values for geography\n",
    "    df['asset_class'] = geography\n",
    "\n",
    "    # create the etf_df on the first loop, else concat to exisiting etf_df.\n",
    "    if etf_df is None:\n",
    "        etf_df = pd.DataFrame()\n",
    "        etf_df = df\n",
    "    else:\n",
    "        etf_df = pd.concat([etf_df, df])\n",
    "\n",
    "# reset the index\n",
    "etf_df.reset_index(inplace=True, drop=True)\n",
    "etf_df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the NAV column to remove the NaN's\n",
    "etf_df = etf_df[etf_df['nav_per_share'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'historical_etf.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "outfile = open(filename, 'wb')\n",
    "\n",
    "pickle.dump(etf_df, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "infile = open(filename, 'rb')\n",
    "historical_etf = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27179, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_etf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Fund Data\n",
    "This section will convert the TD Mutual Fund spreadsheets into usable data and store this information in a pickle file.\n",
    "\n",
    "The mutual fund excel spreadsheets are stored in a subdirectory called mutual_fund data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using the os 'listdir' method to return filenames in the subdirectory\n",
    "path = './mutual_fund_data'\n",
    "mf_files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TD Canadian Bond Index - e.xlsx',\n",
       " 'TD Canadian Index - e.xlsx',\n",
       " 'TD International Index - e.xlsx',\n",
       " 'TD US Index e.xlsx']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_files[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the security symbols in the same order\n",
    "# as the file names in the directory\n",
    "mf_symbol = ['TD_Bond', 'TD_CDN_Equity', 'TD_INT_Equity', 'TD_US_Equity']\n",
    "mf_asset_class = ['Fixed Income', 'Equity', 'Equity', 'Equity'] \n",
    "\n",
    "mf_geography = ['Canadian', 'Canadian', 'International', 'United States']\n",
    "# combine the two list above into a dictionary with the etf symbol as the key.\n",
    "mf_details = zip(mf_files[1:5], mf_asset_class, mf_geography)\n",
    "mf_dict = dict(zip(mf_symbol, mf_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TD Canadian Bond Index - e.xlsx', 'Fixed Income', 'Canadian')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etf_symbol, etf_asset_class, etf_geography, etf_files\n",
    "mf_dict['TD_Bond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize etf_df as none\n",
    "mf_df = None\n",
    "\n",
    "# loop through all the spreadsheets downloaded from iShares and create\n",
    "# one dataframe with all the historical pricing and distribution\n",
    "# information for dates going back to early 2000's\n",
    "\n",
    "for symbol in mf_dict:\n",
    "    file_name = mf_dict[symbol][0]\n",
    "    asset_class = mf_dict[symbol][1]\n",
    "    geography = mf_dict[symbol][2]\n",
    "\n",
    "    # open spread sheet and read the data into df\n",
    "    df = pd.read_excel('mutual_fund_data/' + file_name,\n",
    "                       sheet_name=0,\n",
    "                       names=['trade_date', 'nav_per_share', 'dividends'],\n",
    "                       na_values=\"--\",\n",
    "                       skiprows=1, \n",
    "                       converters={'Date': pd.to_datetime}\n",
    "                       )\n",
    "    # set values in the df for symbol\n",
    "    df['security'] = symbol\n",
    "    \n",
    "    # set values for asset class\n",
    "    df['asset_class'] = asset_class\n",
    "\n",
    "    # set values for geography\n",
    "    df['asset_class'] = geography\n",
    "\n",
    "    # create the etf_df on the first loop, else concat to exisiting etf_df.\n",
    "    if mf_df is None:\n",
    "        mf_df = pd.DataFrame()\n",
    "        mf_df = df\n",
    "    else:\n",
    "        mf_df = pd.concat([mf_df, df])\n",
    "\n",
    "# reset the index\n",
    "mf_df.reset_index(inplace=True, drop=True)\n",
    "mf_df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the NAV column to remove the NaN's\n",
    "mf_df = mf_df[mf_df['nav_per_share'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18764 entries, 0 to 18763\n",
      "Data columns (total 5 columns):\n",
      "trade_date       18764 non-null datetime64[ns]\n",
      "nav_per_share    18764 non-null float64\n",
      "dividends        18764 non-null float64\n",
      "security         18764 non-null object\n",
      "asset_class      18764 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), object(2)\n",
      "memory usage: 879.6+ KB\n"
     ]
    }
   ],
   "source": [
    "mf_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'historical_mf.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mf_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-4ad2e62241d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mf_df' is not defined"
     ]
    }
   ],
   "source": [
    "# save file\n",
    "outfile = open(filename, 'wb')\n",
    "\n",
    "pickle.dump(mf_df, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-cded191c7e34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistorical_mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# load file\n",
    "infile = open(filename, 'rb')\n",
    "historical_mf = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18764, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_mf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the ETF and Mutual Fund Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_mf['fund_type'] = 'Mutual Fund'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_etf['fund_type'] = 'ETF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_history_joined = pd.concat([historical_etf, historical_mf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_history_joined.sort_values(by=['fund_type', 'security', 'trade_date'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type for objects to category\n",
    "price_history = price_history.astype({'security': 'category', 'asset_class': 'category', 'fund_type': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the zero values in dividends in the mutual fund section with np.nan\n",
    "price_history['dividends'] = price_history['dividends'].replace({0:np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45943 entries, 9100 to 13966\n",
      "Data columns (total 6 columns):\n",
      "trade_date       45943 non-null datetime64[ns]\n",
      "nav_per_share    45943 non-null float64\n",
      "dividends        789 non-null float64\n",
      "security         45943 non-null category\n",
      "asset_class      45943 non-null category\n",
      "fund_type        45943 non-null category\n",
      "dtypes: category(3), datetime64[ns](1), float64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "price_history.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'historical_prices.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "outfile = open(filename, 'wb')\n",
    "\n",
    "pickle.dump(price_history, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "infile = open(filename, 'rb')\n",
    "price_history = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45943 entries, 9100 to 13966\n",
      "Data columns (total 6 columns):\n",
      "trade_date       45943 non-null datetime64[ns]\n",
      "nav_per_share    45943 non-null float64\n",
      "dividends        789 non-null float64\n",
      "security         45943 non-null category\n",
      "asset_class      45943 non-null category\n",
      "fund_type        45943 non-null category\n",
      "dtypes: category(3), datetime64[ns](1), float64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "price_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
